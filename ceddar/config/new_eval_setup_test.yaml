# Full run with all settings on
# - Only one condition variable (condition_variables: ["prcp"])
# - Dual LR channel (dual_lr: True and LR_main_var_scale: HR)
# - Predicting residual from LR baseline (edm.predict_residual: True and baseline_space: HR)
# - With sin/cos DOY, only 'season' (sample_w_cond_season: True, use_sin_cos_embedding: True)
# - Geographic conditions (sample_w_geo: True)
# - SDF weighted loss (sdf_weighted_loss: True)
# - EMA (with_ema: True)
# - Classifier-free guidance (classifier_free_guidance.enabled: True)
# - Rain-gating auxiliary loss (rain_gate.enabled: True and reweight_enabled: True)
# - Also predicting in lr space (edm.baseline_space: 'lr' and lrmain_var_scale: 'LR')

experiment:
  name: EDM_final_run
  config_name: EDM_final_run
  # Date of the experiment, taken from the environment variable or set to current date
  date: ${env:EXP_DATE} # Date for the experiment, 

paths:
  data_dir: ${env:DATA_DIR} # Directory for input data
  checkpoint_dir: ${env:CKPT_DIR} # Directory for model checkpoints
  checkpoint_name: sbgm_cfgTest.pth.tar  # Name of the checkpoint file
  sample_dir: ${env:SAMPLE_DIR} # Directory for saving samples
  evaluation_dir: ${env:EVAL_DIR} # Directory for evaluation figures, stats etc.
  log_dir: ${env:LOG_DIR} # Directory for logs
  specific_fig_name: test__plot_fct # Specific figure name to save
  path_save: ${env:SAMPLE_DIR} # Path to save figures
  lsm_path: ${env:DATA_DIR}/data_lsm/truth_fullDomain/lsm_full.npz # Path to land-sea mask data
  topo_path: ${env:DATA_DIR}/data_topo/truth_fullDomain/topo_full.npz # Path to topography data
  slope_path: ${env:DATA_DIR}/data_slope/truth_fullDomain/slope_full.npz # Path to slope data
  stats_load_dir: ${env:STATS_LOAD_DIR} # Directory to load statistics from

highres:
  model: DANRA # Model type for high-resolution data
  variable: prcp # Variable to process
  data_size: [128, 128] # Size of the data to process
  scaling_method: log_zscore # Method for scaling the data
  full_domain_dims: [589, 789]
  buffer_frac: 0.05
  cutout_domains: [170, 350, 340, 520] # [x1, x2, y1, y2], coordinates for cutout
  cutout_name: danra # Name of the cutout (for when wanting North Atlantic later, HR and LR cutouts can be different)
  stationary_cutout: # Whether to use a stationary cutout or random crop from cutout domain (i.e. shifting geographic domain slightly)
    enabled: false # Whether to use a stationary cutout or random crop from cutout domain (i.e. shifting geographic domain slightly)
    bounds: [200, 328, 380, 508] # [y0, y0+128, x0, x0+128] bounds in full domain for HR data (for stationary cutout)

lowres:
  model: ERA5 # Model type for low-resolution data
  full_domain_dims: [589, 789]
  condition_variables: ["prcp"] # ["temp", "prcp"] # Variables for conditioning
  scaling_methods: ["log_zscore"] #["zscore", "log_zscore"] # Scaling methods for low-res data
  dual_lr: true # Whether to use dual (one scaled w. global (HR+LR) statistics, one with LR stats) low-res (prcp or temp) data. When true, LR parsed in two channels, one scaled w. LR stats, one w. HR+LR stats
  lr_main_var_scale: "HR" # Which statistics to use for scaling the main low-res variable (prcp or temp) when dual_lr is False ("LR": lr only, "HR": hr only, "HR_LR": both)
  lr_main_var_scale_method: "log_zscore" # Which scaling method to use for the main low-res variable (prcp or temp) when dual_lr is False
  buffer_frac: 0.05
  data_size: [128, 128] # Size of the low-res data
  resize_factor: 1 # Factor to resize low-res data (used for testing at lower resolutions)
  cutout_domains: [170, 350, 340, 520] # [x1, x2, y1, y2], coordinates for cutout
  cutout_name: danra # Name of the cutout (for when wanting North Atlantic later, HR and LR cutouts can be different). If HR and LR cutouts are the same, they will be co-located
  stationary_cutout: # Whether to use a stationary cutout or random crop from cutout domain
    enabled: false # Whether to use a stationary cutout or random crop from cutout domain (i.e. shifting geographic domain slightly)
    bounds: [200, 328, 380, 508] # [y0, y0+128, x0, x0+128] bounds in full domain for HR data (for stationary cutout)

sampler:
  sampler_type: edm_sampler #pc_sampler # Type of sampler to use
  n_timesteps: 56 # Number of timesteps for sampling (EDM: suggested 35-50)
  time_embedding: 256 # Dimension of time embedding
  last_fmap_channels: 512 # Channels in the last feature map
  num_heads: 4 # Number of attention heads
  block_layers: [2, 2, 2, 2] # Number of layers in each block

data_handling:
  cache_size: 0 # Size of the cache for data handling
  cache_size_train: 0 # Size of the cache for data handling
  cache_size_valid: 0 # Size of the cache for validation data
  cache_size_gen: 0 # Size of the cache for test data
  num_workers: ${env:SLURM_CPUS_PER_TASK} # Number of workers for data loading
  n_gen_samples: 8 # Number of generated samples (for visualization)
  pin_memory: true # Whether to pin memory for faster data transfer

transforms:
  scaling: true # Whether to apply scaling
  scaling_split: all # Which data split to use for computing scaling statistics (train, valid, test or all)
  force_matching_scale: false # Whether to force matching scale
  sample_w_cutouts: true # Whether to sample with cutouts
  prcp_eps: 0.01 # Small epsilon value for precipitation data to avoid log(0)
  

stationary_conditions:
  geographic_conditions:
    sample_w_geo: true # Whether to sample with geographic conditions
    sample_w_sdf: true # Whether to sample with SDF (Signed Distance Function)
    geo_variables: ['lsm', 'topo'] # Geographic variables to include, 'slope' can be added
    with_mask: false # Whether to include classifier-free guidance mask
    topo_min: -12 # Minimum value for topography visualization
    topo_max: 12 # Maximum value for topography visualization
    norm_min: -1 # Minimum normalization value for topography and slope
    norm_max: 1 # Maximum normalization value for topography and slope
    max_land_weight: 1.0 # Maximum weight for land in SDF
    min_ocean_weight: 0.5 # Minimum weight for ocean in SDF
    topo_dx_m: 1000.0 # Grid spacing in meters (x)
    topo_dy_m: 1000.0 # Grid spacing in meters (y)
  seasonal_conditions:
    sample_w_cond_season: true # Whether to sample with seasonal conditions
    use_sin_cos_embedding: true # Whether to use sin/cos embedding for seasonal conditions
    use_leap_years: true # Whether to account for leap years in seasonal conditions
    n_seasons: 4 # Number of seasons in the data
    

visualization:
  transform_back_bf_plot: true # Whether to transform back before plotting
  create_figs: true # Whether to create figures during visualization
  gen_and_plot_every_n_epochs: 10 # Frequency (in epochs) to generate samples during training
  save_figs: true # Whether to save figures 
  plot_losses: true # Whether to plot losses
  plot_initial_sample: true # Whether to plot first samples
  show_figs: false # Whether to show figures during visualization
  show_both_orig_scaled: false # Whether to show both original and scaled data
  show_geo: true # Whether to show geographic information
  show_ocean: false # Whether to show ocean data
  overlay_lsm_contour: true # Whether to overlay contour on initial plot (can be added to other plots if needed)
  force_matching_scale: true # Whether to force matching scale in visualization
  add_boxplot_per_panel: true # Whether to add boxplot per panel in visualization
  add_boxplot_summary: true # Whether to add summary boxplot in visualization
  plot_dual_lr_channel: 0 # What LR channel to plot when dual_lr is True (0 or 1)
  # summary_boxplot_keys: # <-- optional; overrides default [generated, hr, matching-lr]
  #   - generated
  #   - prcp_hr
  #   - prcp_lr


model:
  use_resize_conv: false # true -> bilinear + 3x3, false -> transposed conv
  decoder_norm: "group" # Type of normalization in the decoder "instance" | "group"
  decoder_gn_groups: 8 # Number of groups for group normalization (if used)
  decoder_activation: "SiLU" # Activation function in the decoder "ReLU" | "SiLU" | "GELU" (SiLU smoother than ReLU)


training:
  seed: 504 # Random seed for reproducibility
  device: cuda # Device to use for training (e.g., 'cuda' or 'cpu')
  use_mixed_precision: false # Whether to use mixed precision training
  use_grad_clip: false # Whether to use gradient clipping
  grad_clip_norm: 0.0 # Gradient clipping norm (sset to None to disable)
  verbose: true # Whether to print verbose output during training
  batch_size: 16 # Batch size for training
  learning_rate: 0.0002 # Learning rate for training
  min_lr: 0.0000005 # Minimum learning rate
  lr_scheduler: ReduceLROnPlateau # Learning rate scheduler to use
  lr_scheduler_params: # ReduceLROnPlateau
    factor: 0.5 # Factor by which to reduce the learning rate
    patience: 15 # Patience for the scheduler
    threshold: 0.01 # Threshold for the scheduler
    min_lr: 1e-6 # Minimum learning rate for the scheduler
  weight_init: true # Whether to initialize weights
  custom_weight_initializer: !!null # Custom weight initializer (if any) - currently not used, but should be 'kaiming', 'he' or 'xavier'
  with_ema: true # Whether to use Exponential Moving Average. If false, all EMA params below are ignored
  eval_use_ema: true # Whether to use EMA weights for evaluation (validation and generation)
  load_ema: true # Whether to load EMA weights
  ema_decay: 0.999 # Decay rate for EMA. 0.999-0.9995 is a good range for per-step decay with batch size 16-32. Lower for smaller batches, higher for larger batches.
  weight_decay: 0.000001 # Weight decay for regularization
  ema_warmup_steps: 2000 # Number of warmup steps for EMA
  epochs: 400 # Number of epochs for training
  loss_type: sdfweighted # Type of loss function to use
  sdf_weighted_loss: true # Whether to use SDF weighted loss
  optimizer: adamw # Optimizer to use for training (adam, adamw, sgd) (adamw for better decay)
  load_checkpoint: false # Whether to load a checkpoint
  early_stopping: true # Whether to use early stopping
  early_stopping_params:
    patience: 75 # Patience for early stopping
    min_delta: 0.0001 # Minimum delta for early stopping
  train_use_amp: false # Whether to use automatic mixed precision
  train_postfix_every: 10 # Frequency of printing training postfix
  detect_anomaly: false # Whether to detect anomalies (NaNs/Infs) during training
  debug_device_asserts: false # Whether to enable device asserts for debugging
  debug_pre_sigma_div: false # Whether to enable pre-sigma division debugging in the model

classifier_free_guidance:
  enabled: false # Whether to use classifier-free guidance
  drop_prob_lr: 0.1 # Dropout probability for guidance on LR conditions, [0.1 - 0.2]. If over-conditioning (model copies LR too much), increase.
  drop_prob_geo: 0.1 # Optional: lower drop for static geo; else omit and use drop_prob [0.05-0.1]. If spatial artifacts when geo present, reduce.. Keep drop_prob_geo <= drop_prob
  guidance_scale: 1.0 # Scale for guidance 
  null_label_id: 0 # Use 0 as "null" in label embedding 
  null_scalar_value: 0.0 # Use -1 as "null" for continuous scalar conditions (e.g. seasons as cos/sin)
  guidance_scale_max: 3.0 # Maximum scale for guidance
  sigma_weighted: true # Whether to weight guidance scale with sigma (True recommended, False for ablation)
  drop_lr_ups_in_uncond: true # Whether to drop lr_ups in unconditional branch (True recommended, False for ablation)

edm:
  enabled: true # Whether to use EDM (Elucidated Diffusion Models)
  P_mean: -1.5 # Mean P for EDM
  P_std: 1.2 # Standard deviation of P for EDM
  sigma_data: 1.0 # Data is assumed N(0,1) after normalization
  sigma_min: 0.002 # Minimum sigma for EDM
  sigma_star: 1.0 # Sigma star for EDM (training)
  sigma_max: 80 # Maximum sigma for EDM
  rho: 7.0 # Rho parameter for EDM
  # Starting with modest churn, can increase later if samples too smooth
  S_churn: 2.0 # Churn parameter for EDM
  S_min: 40.0 # Minimum S for EDM (about 0.5 * sigma_max, typically)
  S_max: 80.0 # Maximum S for EDM (typically equal to sigma_max)
  S_noise: 1.0 # Noise parameter for EDM
  sampling_steps: 56 # Number of sampling steps for EDM (suggested: 35-50)
  predict_residual: true # Whether to predict residual from LR baseline
  baseline_space: hr # Which z-space to use for lr_ups baseline: 'hr' | 'lr' | 'auto' (auto prefers *_hrspace if available)  
  drop_lr_ups_in_uncond: true # Whether to drop lr_ups in unconditional branch (True recommended, False for ablation)

rain_gate:
  enabled: true # Whether to use rain-gating auxiliary loss
  include_lsm: true # Whether to include land-sea mask as input to rain-gate head
  include_topo: true # Whether to include topography as input to rain-gate head
  include_lr_baseline: true # Whether to include lr_baseline as input to rain-gate head
  wet_threshold_mm: 0.1 # Threshold in mm/day for wet/dry classification when computing BCE loss
  wet_threshold_modelSpace: -10.0 # Threshold in model space (e.g. z-score) for wet/dry classification when computing BCE loss
  loss_weight_bce: 0.02 # Weight of the BCE loss for rain gate
  pos_weight: 1.15 # Positive class weight for BCE loss to handle class imbalance
  c_hidden: 16 # Number of channels in hidden layers of rain-gate head
  learning_rate: 0.0002 # Learning rate for rain gate head

  # Selective, softer, reweighting of diffusion loss based on rain-gate predictions
  reweight_enabled: true # Whether to reweight diffusion loss based on rain-gate predictions
  weight_strategy: binary # Strategy for reweighting: 'prob' (use predicted probabilities), 'binary' (use binary predictions)
  weight_alpha: 0.5 # Extra weight on wet pixels when reweighting
  prob_gamma: 2.0 # Exponent for probabilities when reweighting (if using 'prob' strategy)
  clip_max: 1.8 # Maximum clipping value for weights when reweighting
  detach_weights: true # Whether to detach weights from computation graph when reweighting (recommended)
  reweight_warm_start_epochs: 10 # Delay reweighting until after this many epochs (allows rain-gate to learn first)
  reweight_ramp_epochs: 10 # Optional: ramp strength for 5 epochs after warm start
  binary_threshold: 0.5 # Threshold for binary classification when reweighting (if using 'binary' strategy)

scale_control:
  enabled: false # Whether to use scale control auxiliary loss
  method: auto_from_psd # or 'manual'
  preserve_scale_km: null # If set, overrides auto_from_psd
  pixel_km: 2.5 # Pixel size in km (for auto_from_psd)
  land_only: true # Whether to compute scale control loss on land only
  window: hann # Window type for FFT (e.g., 'hann', 'hamming', 'blackman')
  c_sigma: 1.0 # 0.8-1.2 for balancing low/high freq emphasis

ve_dsm: # Default parameters for VE-DSM loss
  t_eps: 1e-3 # Small epsilon for VE-DSM

monitoring:
  edm_metrics_enabled: true # Whether to enable EDM metrics monitoring
  edm_metrics_every: 100 # Frequency (in steps) to compute EDM metrics
  edm_cosine_metric: true # Whether to compute the cosine similarity metric
  plot_every_n_epochs: 5 # Frequency (in epochs) to plot training metrics
  backtransform_extreme_prcp: true # Whether to back-transform extreme precipitation for monitoring
  end_of_epoch:
    enabled: true # Whether to enable end-of-epoch monitoring
    eval_batches: 1 # How many gen batches to use for end-of-epoch evaluation
    grid_km_per_px: 2.5 # Grid spacing in km/px
    fss_km: [5, 10, 20] # FSS thresholds in km 
    fss_threshold_mm: 1.0 # 1 mm/day event FSS; adjust if needed
    psd_band: [0.05, 0.40] # radial frequency fraction for slope fit
    wet_day_threshold_mm: 0.1 # Threshold for wet day in mm/day 
    psd_compare_to_hr: true # Whether to compare generated samples PSD to high-resolution data PSD
    quantiles_compare_to_hr: true # Whether to compare generated samples quantiles to high-resolution data quantiles

diagnostics:
  per_batch_stats: true # Whether to compute per-batch statistics
  log_every: 100 # Frequency (in steps) to log training statistics
  model_outputs: false # Whether to log model outputs
  warn_if_abs_gt: 15.0 # Warn if any abs value greater than this
  warn_if_phys_gt: 350.0 # Warn if any physical value greater than this (after back-transform)
  save_histograms: true # Whether to save histograms of model outputs
  histogram_bins: 200 # Number of bins for histograms
  histogram_range: null # Range for histograms (null for automatic range)
  histogram_every: 500 # Frequency (in steps) to save histograms
  histogram_path: ${env:LOG_DIR}/histograms # Path to save histograms

evaluation:
  # Legacy / low-level evaluation settings.
  # Full evaluation orchestration is handled by the `full_gen_eval` block below.
  # This block is kept only for geometry / stationarity used by data loading
  # and GenerationRunner (e.g. static LSM cropping).
  stationary_cutout:
    hr_enabled: true   # Use stationary HR cutout during evaluation/generation
    lr_enabled: true   # Use stationary LR cutout during evaluation/generation
    cutout_domains: [170, 350, 340, 520]  # Full cutout domain in the original grid
    hr_bounds: [200, 328, 380, 508]       # [y0, y1, x0, x1] for HR evaluation cutout
    lr_bounds: [200, 328, 380, 508]       # [y0, y1, x0, x1] for LR evaluation cutout

generation:
  fixed_dates: true # Whether to use same fixed dates every epoch for generation
  random_dates: false # Whether to use random dates for generation (either random or sequential)
  start_index: 0 # Start index for fixed dates
  seed: 504 # Random seed for fixed dates

  logging:
    file_level: INFO # Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    console_level: WARNING # Console logging level
    # log_to_file: true # Whether to log to a file
    # log_to_console: true # Whether to log to console
    # log_dir: ${env:LOG_DIR} # Directory for logs
    # log_filename: training.log # Filename for the log file
    # save_config: true # Whether to save the configuration to a file
    # config_filename: config.yaml # Filename for the saved configuration


full_gen_eval:
  split: test
  use_new_eval: true
  seed: 504 # Random seed for full evaluation
  sampler_cleanup: true

  sigma_star_grid: [0.80, 0.85, 0.90, 0.95, 1.00, 1.05, 1.10, 1.15, 1.20, 1.25]

  sigma_control:
    sigma_star_mode: late_ramp
    ramp_start_frac: 0.60
    ramp_end_frac: 0.85
    example_sigma_subset: [0.80, 0.90, 1.00, 1.10, 1.20]
    crps_rain_thresh: 1.0
    hk_min_hr_frac: 1.0e-4
    hk_min_hr_abs: 1.0e-12

  sampler_grid:
    rho: [9.0]          # Best rho
    S_churn: [2.0]      # Best S_churn
    sigma_scale: [1.10] # best sigma_scale
  
  sampler_eval_tasks: ["prcp_probabilistic",
                       "prcp_extremes",
                       "prcp_scale",
                       "prcp_distributional",
                       "prcp_spatial"]

  ensemble_size: 32 # Number of ensemble members to generate for full evaluation
  max_dates: 800 # Maximum number of dates to evaluate (set to -1 for all available dates)
  eval_land_only: true
  prefer_phys: true
  lr_key: lr # lr | lr_lrspace | lr_hrspace
  make_plots: true
  
  hr_dx_km: 2.5 # High-resolution grid spacing in km
  lr_dx_km: 31.0 # Low-resolution grid spacing in km
  grid_km_per_px: 2.5 # Grid spacing in km/px
  lr_grid_km_per_px: 31 # LR grid spacing in km/px

  # Ensemble evaluation config fields
  use_ensemble: true
  ensemble_n_members: null # optional sub-sample, null for all
  ensemble_member_seed: 1234
  ensemble_reduction_fallback: pmm
  ensemble_cache_members: false
  dist_ensemble_pool_mode: pool # pool | member_mean
  
  # Which tasks to perform.
  do_prob: true
  do_scale: true
  do_dist: true
  do_ext: true
  do_spat: true
  do_temp: true
  do_feat: true
  do_dates: true
  plot_only: false  

  # Benchmark overlay settings
  baselines_overlay:
    enabled: false
    types: [qm, unet_sr] # any subset. Order is plot order "bilinear", "qm", "unet_sr"
    split: test # train | valid | test
    labels:
      bilinear: "LR bilinear"
      qm: "QM (per-pixel)"
      unet_sr: "UNet-SR"
    # optional styling overrides
    styles:
      bilinear: {color: '#c47a02', ls: "--", lw: 0.8}
      qm:       {color: '#008b8b', ls: "-.", lw: 0.8}
      unet_sr:  {color: '#7a68a6', ls: ":", lw: 0.8}

  gen_dir: null # Directory for generation outputs (if null, use default)
  eval_dir: null # Directory for evaluation outputs (if null, use default)

  fss_threshold_mm: [1.0, 5.0, 10.0, 20.0, 50.0] # FSS threshold in mm/day
  fss_scales_km: [5, 10, 20, 40] # FSS scales in km
  compute_lr_fss: true # Whether to compute FSS on LR grid
  
  iss_thresholds_mm: [1.0, 5.0, 10.0, 20.0, 50.0] # Thresholds in km for ISS (if null, use fss_threshold_mm)
  iss_scales_km: [5, 10, 20, 40] # Scales in km for ISS (if null, use fss_scales_km)
  compute_lr_iss: true 

  thresholds_mm: [1.0, 5.0, 10.0, 20.0] # Thresholds in mm/day for categorical metrics
  wet_threshold_mm: 0.5 # Threshold for wet day in mm/day

  reliability_bins: 10 # 
  spread_skill_bins: 10
  pit_bins: 20 # Number of bins for PIT histogram

  variogram_p: 0.5 # 
  variogram_max_pairs: 5000

  psd_ignore_low_k_bins: 2
  psd_normalize: none # "none" | "per_field" | "match_ref"
  low_k_max: 0.005 # 1/200 km^-1
  high_k_max: 0.05 # 1/20 km^-1

  random_ref_kind: phase_randomized
  seasonal_summaries: true
  region_mask_path: null

  pixel_dist_n_bins: 100
  pixel_dist_vmax_percentile: 99.5
  pixel_dist_save_cap: 20_000_000
  pixel_dist_include_lr: true

  # --- extremes ---
  ext_agg_kind: "mean"            # "mean" or "sum" over masked HR domain per day
  ext_rxk_days: [1, 5]            # Rx1day, Rx5day
  ext_gev_rps_years: [2, 5, 10, 20, 50]
  ext_blocks_per_year: 12.0        # 4.0 = seasonal GEV (DJF/MAM/JJA/SON), 12.0 = monthly GEV
  ext_pot_thr_kind: "hr_quantile"    # "quantile" or "value"
  ext_pot_thr_val: 0.95           # if kind="quantile" → 95th pct; if "value" → mm/day
  ext_pot_rps_years: [2, 5, 10, 20, 50]
  ext_days_per_year: 365.25
  ext_wet_threshold_mm: 1.0
  ext_include_lr: true           # LR series collection; plots currently focus on HR vs GEN
  ext_tails_basis: pooled_pixels

  # spatial
  spatial_corr_kinds: ["pearson", "spearman"] # 
  spatial_deseasonalize: True
  spatial_vmin: null
  spatial_vmax: null
  spatial_show_diff: true
  spatial_include_gen: false
  spatial_include_ens: true
  spatial_include_hr:  true
  spatial_include_lr:  true

  # temporal
  temporal_include_lr: true
  temporal_wet_thr_mm: 1.0
  temporal_max_lag: 30
  temporal_max_spell: 25
  temporal_group_by: year # | year | season | all
  temporal_ensemble_pool_mode: member_mean # member_mean | pool

  # features
  sal_structure_mode: object        # or: std_proxy
  sal_threshold_kind: quantile      # or: absolute
  sal_threshold_value: 0.85         # 90th percentile OR absolute mm/day. 0.85 means keep more mesoscale structure
  sal_connectivity: 8               # 4 or 8
  sal_min_area_px: 16               # 9: 3x3 kernel. 16 or 25 to reduce salt-and-pepper, and stabilize S
  sal_smooth_sigma: 1.0             # optional, helps noisy data. Higher smoothing -> smaller ensemble spread result
  sal_peakedness_mode: herfindahl

  # dates
  dates_list: ["20190107", "20190203", "20190312"]
  dates_include_lr: true
  dates_include_members: true
  dates_n_members: 3
  dates_cmap: "auto"
  dates_percentile: 99.5



quicklook: # Quicklook generation settings
  n_dates: 6 # Number of dates to generate quicklooks for
  members_to_show: 5 # Number of ensemble members to show in quicklook
  sampler_steps: null # Number of sampler steps (if null, use training config)
  seed: null # Random seed (if null, random)
  specific_dates: null # List of specific dates (YYYY-MM-DD) to generate quicklooks for (if null, random)
  vmax_mm: null # Max value for colorbar in mm/day (if null, automatic)
  save_png: true # Whether to save quicklook PNGs